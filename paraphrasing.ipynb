{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c69966ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load eval data\n",
    "import pandas as pd\n",
    "\n",
    "# synonym replacement libraries\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "\n",
    "# t5 paraphrasing libraries\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# LLM paraphrasing libraries\n",
    "from ollama import chat\n",
    "from ollama import ChatResponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "942e477f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>question1_token_len</th>\n",
       "      <th>question2_token_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>229726</td>\n",
       "      <td>32797</td>\n",
       "      <td>55300</td>\n",
       "      <td>What's the best way to learn Python?</td>\n",
       "      <td>Where should I start at to learn about how to ...</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66828</td>\n",
       "      <td>32100</td>\n",
       "      <td>115759</td>\n",
       "      <td>Were the IRA freedom fighters or terrorists?</td>\n",
       "      <td>Is the IRA a group of freedom fighters or terr...</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id   qid1    qid2                                     question1  \\\n",
       "0  229726  32797   55300          What's the best way to learn Python?   \n",
       "1   66828  32100  115759  Were the IRA freedom fighters or terrorists?   \n",
       "\n",
       "                                           question2  is_duplicate  \\\n",
       "0  Where should I start at to learn about how to ...             1   \n",
       "1  Is the IRA a group of freedom fighters or terr...             1   \n",
       "\n",
       "   question1_token_len  question2_token_len  \n",
       "0                    7                   12  \n",
       "1                    7                   11  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df = pd.read_csv(\"./data/val.csv\")\n",
    "eval_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "825d7d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "paraphrased_eval_df = eval_df.copy()\n",
    "# For time constraints, we will only use 300 samples\n",
    "paraphrased_eval_df = paraphrased_eval_df.sample(n=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af01db7f",
   "metadata": {},
   "source": [
    "# 1. Paraphrasing with simple synonym replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec51267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('punkt_tab')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('averaged_perceptron_tagger_eng')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9c76215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(tag):\n",
    "    \"\"\"Map NLTK POS tag to WordNet POS tag\"\"\"\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def synonym_replacement(sentence):\n",
    "    \"\"\"\n",
    "    Simple paraphrasing by replacing nouns and verbs with their synonyms\n",
    "    \"\"\"\n",
    "    tokens = word_tokenize(sentence)\n",
    "    tagged = pos_tag(tokens)\n",
    "    \n",
    "    new_tokens = tokens.copy()\n",
    "    \n",
    "    # Replace 1-3 words with synonyms\n",
    "    replaceable = []\n",
    "    for i, (word, tag) in enumerate(tagged):\n",
    "        pos = get_wordnet_pos(tag)\n",
    "        if pos in [wordnet.NOUN, wordnet.ADJ] and len(word) > 2:\n",
    "            replaceable.append(i)\n",
    "    \n",
    "    # If we found replaceable words, replace 1-3 of them\n",
    "    if replaceable:\n",
    "        num_to_replace = min(len(replaceable), random.randint(1, 3))\n",
    "        indices_to_replace = random.sample(replaceable, num_to_replace)\n",
    "        \n",
    "        for idx in indices_to_replace:\n",
    "            word, tag = tagged[idx]\n",
    "            pos = get_wordnet_pos(tag)\n",
    "            \n",
    "            # Get synonyms\n",
    "            synonyms = []\n",
    "            for syn in wordnet.synsets(word.lower(), pos=pos):\n",
    "                for lemma in syn.lemmas():\n",
    "                    synonym = lemma.name().replace('_', ' ')\n",
    "                    if synonym != word.lower() and synonym not in synonyms:\n",
    "                        synonyms.append(synonym)\n",
    "            \n",
    "            # Replace with a synonym if we found any\n",
    "            if synonyms:\n",
    "                synonym = random.choice(synonyms)\n",
    "                # Maintain capitalization\n",
    "                if word[0].isupper():\n",
    "                    synonym = synonym.capitalize()\n",
    "                new_tokens[idx] = synonym\n",
    "    \n",
    "    return ' '.join(new_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d259bd1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>synonym_replacement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2738</th>\n",
       "      <td>How do I find a hacker?</td>\n",
       "      <td>How do I find a cyberpunk ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>What would the sky look like if Andromeda was ...</td>\n",
       "      <td>What would the sky look like if Japanese andro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>Is world war 3 likely?</td>\n",
       "      <td>Is domain state of war 3 likely ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1694</th>\n",
       "      <td>What are the career options after electrical e...</td>\n",
       "      <td>What are the calling options after electrical ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1782</th>\n",
       "      <td>What are the chances that the electoral colleg...</td>\n",
       "      <td>What are the chance that the electoral college...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question1  \\\n",
       "2738                            How do I find a hacker?   \n",
       "816   What would the sky look like if Andromeda was ...   \n",
       "1258                             Is world war 3 likely?   \n",
       "1694  What are the career options after electrical e...   \n",
       "1782  What are the chances that the electoral colleg...   \n",
       "\n",
       "                                    synonym_replacement  \n",
       "2738                        How do I find a cyberpunk ?  \n",
       "816   What would the sky look like if Japanese andro...  \n",
       "1258                  Is domain state of war 3 likely ?  \n",
       "1694  What are the calling options after electrical ...  \n",
       "1782  What are the chance that the electoral college...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paraphrased_eval_df[\"synonym_replacement\"] = paraphrased_eval_df[\"question1\"].apply(synonym_replacement)\n",
    "paraphrased_eval_df[[\"question1\", \"synonym_replacement\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e83c2a8",
   "metadata": {},
   "source": [
    "# 2. Paraphrasing with finetuned t5 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc9c4244",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t5_paraphrase(\n",
    "    question,\n",
    "    num_beams=3,\n",
    "    num_beam_groups=3,\n",
    "    num_return_sequences=3,\n",
    "    repetition_penalty=10.0,\n",
    "    diversity_penalty=3.0,\n",
    "    no_repeat_ngram_size=2,\n",
    "    temperature=0.7,\n",
    "    max_length=64\n",
    "):\n",
    "    input_ids = tokenizer(\n",
    "        f'paraphrase: {question}',\n",
    "        return_tensors=\"pt\", padding=\"longest\",\n",
    "        max_length=max_length,        \n",
    "        truncation=True,\n",
    "    ).input_ids\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        input_ids,temperature=temperature,repetition_penalty=repetition_penalty,\n",
    "        num_return_sequences=num_return_sequences, no_repeat_ngram_size=no_repeat_ngram_size,\n",
    "        num_beams=num_beams, num_beam_groups=num_beam_groups,\n",
    "        max_length=max_length, diversity_penalty=diversity_penalty\n",
    "    )\n",
    "\n",
    "    res_list = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    res_list = [r for r in res_list if r != question]\n",
    "    res = random.choice(res_list)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0ff6293",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/llm_env/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Paraphrasing with the fine-tuned T5 model\n",
    "# Load model and tokenizer\n",
    "device = \"cpu\"\n",
    "model_name = \"coco101010/t5-paraphrase-quora-finetuned\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n",
    "\n",
    "paraphrased_eval_df[\"finetuned_t5\"] = paraphrased_eval_df[\"question1\"].apply(lambda x: t5_paraphrase(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f592489b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "/opt/anaconda3/envs/llm_env/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Paraphrasing with the original T5 model\n",
    "# Load model and tokenizer\n",
    "model_name = \"Vamsi/T5_Paraphrase_Paws\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n",
    "\n",
    "paraphrased_eval_df[\"original_t5\"] = paraphrased_eval_df[\"question1\"].apply(lambda x: t5_paraphrase(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "817bcb33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/llm_env/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Paraphrasing with the GPT T5 model\n",
    "model_name = \"humarin/chatgpt_paraphraser_on_T5_base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n",
    "\n",
    "paraphrased_eval_df[\"gpt_t5\"] = paraphrased_eval_df[\"question1\"].apply(lambda x: t5_paraphrase(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db0f0610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>finetuned_t5</th>\n",
       "      <th>original_t5</th>\n",
       "      <th>gpt_t5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2738</th>\n",
       "      <td>How do I find a hacker?</td>\n",
       "      <td>What are the best ways to find a hacker?</td>\n",
       "      <td>What is the best way to find a hacker?</td>\n",
       "      <td>Is there a way to find if someone is hacking?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>What would the sky look like if Andromeda was ...</td>\n",
       "      <td>How would the sky look if Andromeda collided w...</td>\n",
       "      <td>How the sky would look if Andromeda was right ...</td>\n",
       "      <td>How would the sky appear if Andromeda collided...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>Is world war 3 likely?</td>\n",
       "      <td>Is world war 3 possible?</td>\n",
       "      <td>Is world war 3 probable?</td>\n",
       "      <td>Is the possibility of world war 3 a realistic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1694</th>\n",
       "      <td>What are the career options after electrical e...</td>\n",
       "      <td>How can I get a career in electrical engineeri...</td>\n",
       "      <td>What are career options after electrical engin...</td>\n",
       "      <td>Apart from multinational corporations, what ot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1782</th>\n",
       "      <td>What are the chances that the electoral colleg...</td>\n",
       "      <td>What are the chances that the electoral colleg...</td>\n",
       "      <td>What are the chances that if Hillary wins the ...</td>\n",
       "      <td>In the event that Hillary wins the popular vot...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question1  \\\n",
       "2738                            How do I find a hacker?   \n",
       "816   What would the sky look like if Andromeda was ...   \n",
       "1258                             Is world war 3 likely?   \n",
       "1694  What are the career options after electrical e...   \n",
       "1782  What are the chances that the electoral colleg...   \n",
       "\n",
       "                                           finetuned_t5  \\\n",
       "2738           What are the best ways to find a hacker?   \n",
       "816   How would the sky look if Andromeda collided w...   \n",
       "1258                           Is world war 3 possible?   \n",
       "1694  How can I get a career in electrical engineeri...   \n",
       "1782  What are the chances that the electoral colleg...   \n",
       "\n",
       "                                            original_t5  \\\n",
       "2738             What is the best way to find a hacker?   \n",
       "816   How the sky would look if Andromeda was right ...   \n",
       "1258                           Is world war 3 probable?   \n",
       "1694  What are career options after electrical engin...   \n",
       "1782  What are the chances that if Hillary wins the ...   \n",
       "\n",
       "                                                 gpt_t5  \n",
       "2738      Is there a way to find if someone is hacking?  \n",
       "816   How would the sky appear if Andromeda collided...  \n",
       "1258  Is the possibility of world war 3 a realistic ...  \n",
       "1694  Apart from multinational corporations, what ot...  \n",
       "1782  In the event that Hillary wins the popular vot...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paraphrased_eval_df[[\"question1\", \"finetuned_t5\", \"original_t5\", \"gpt_t5\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423396fe",
   "metadata": {},
   "source": [
    "# 3. Paraphrasing with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "10303194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can I recover my Instagram DM?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def LLM_paraphrase(question):\n",
    "    response: ChatResponse = chat(model='gemma3:1b', messages=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': \"\"\"Give 1 paraphrase for the following question, output the paraphrase only.\n",
    "            \"\"\" + question,\n",
    "        },\n",
    "    ])\n",
    "    return response.message.content\n",
    "\n",
    "print(LLM_paraphrase(\"How can I get back my instagram deleted dms?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95f7f40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "paraphrased_eval_df[\"llm\"] = paraphrased_eval_df[\"question1\"].apply(lambda x: LLM_paraphrase(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10f4dd27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>llm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2738</th>\n",
       "      <td>How do I find a hacker?</td>\n",
       "      <td>What's the best way to identify a hacker?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>What would the sky look like if Andromeda was ...</td>\n",
       "      <td>What would the sky appear to be like during a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>Is world war 3 likely?</td>\n",
       "      <td>Is there a high probability of a large-scale g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1694</th>\n",
       "      <td>What are the career options after electrical e...</td>\n",
       "      <td>What other career paths are available to engin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1782</th>\n",
       "      <td>What are the chances that the electoral colleg...</td>\n",
       "      <td>What is the probability that the Electoral Col...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question1  \\\n",
       "2738                            How do I find a hacker?   \n",
       "816   What would the sky look like if Andromeda was ...   \n",
       "1258                             Is world war 3 likely?   \n",
       "1694  What are the career options after electrical e...   \n",
       "1782  What are the chances that the electoral colleg...   \n",
       "\n",
       "                                                    llm  \n",
       "2738          What's the best way to identify a hacker?  \n",
       "816   What would the sky appear to be like during a ...  \n",
       "1258  Is there a high probability of a large-scale g...  \n",
       "1694  What other career paths are available to engin...  \n",
       "1782  What is the probability that the Electoral Col...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paraphrased_eval_df[[\"question1\", \"llm\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a21a53",
   "metadata": {},
   "source": [
    "# Save paraphrased data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a7d9592f",
   "metadata": {},
   "outputs": [],
   "source": [
    "paraphrased_eval_df.to_csv(\"data/paraphrased_eval.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
